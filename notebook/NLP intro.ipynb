{"cells":[{"metadata":{},"cell_type":"markdown","source":"![](../input/cover.png)"},{"metadata":{"nbpresent":{"id":"d845fa01-43ae-4c70-a262-b02bea70a1f8"}},"cell_type":"markdown","source":"# Natural Language Processing (NLP)\n### Luis Andrade\n\n\n"},{"metadata":{"nbpresent":{"id":"1c70b7fb-ca89-4f5a-8d79-b8e91f26333a"},"trusted":true},"cell_type":"code","source":"import warnings\nimport os\n\nwarnings.filterwarnings('ignore')\nWORK_DIR = [\"..\", \"input\", \"nlp-tutorial\"] # files needed to run the notebook\nDATA_DIR = [\"..\", \"input\", \"word2vec-nlp-tutorial\"]# contains the dataset from the bag of popcorn\n# get this dataset from Kaggle at https://www.kaggle.com/c/word2vec-nlp-tutorial","execution_count":2,"outputs":[]},{"metadata":{"nbpresent":{"id":"07223a7d-2723-4123-bfbd-2725764b1528"}},"cell_type":"markdown","source":"## Contents\n1. Introduction\n2. Preprocessing\n3. Feature Extraction\n    * Bag of Words\n    * TF-IDF\n    * Word Embeddings\n3. Text Classification Example\n4. Conclusions\n\n### Objective\nBy the end of this session, participants will be able to understand basic NLP techniques \n\n"},{"metadata":{"nbpresent":{"id":"064ee844-7969-4d16-b082-c7991994f3ce"}},"cell_type":"markdown","source":"### Introduction\n* NLP is an area of computer science and AI concerned with the interactions between computers and human (natural) languages\n* Most of human knlowledge is actually in the form of raw unstructured text.\n* Learning how to process this information can thus greatly increase the insights that can be generated from data\n\n<img src=\"../input/nlp-tutorial/natural-Language-processing.PNG\" alt=\"drawing\" width=\"400px\"/>\n\nSome of the main tasks and areas of research of NLP are:\n\n- Machine translation\n- Named entity recognition\n- Chatbots \\ Question answering\n- Text to speech\n- Relation extraction\n- Text generation\n- Sentiment Analysis\n\n#### Machine Learning with Text\n\n\n\n<img src=\"../input/text_ml_workflow.png\"/>\n\n\n\n#### Jargon\nCorpora - A set of documents\n   - English languange, Portuguese...\n    \nLexicon- Words and their meanings\n   - Investing jargon vs regular english speak (Bull, Bear...) \n\n[Token](https://en.wikipedia.org/wiki/Lexical_analysis#Token) - String with an assigned and thus identified meaning\n   - Keywords, separators, literals...\n\nStopwords - Most common words in a language"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip freeze","execution_count":3,"outputs":[{"output_type":"stream","text":"absl-py==0.7.1\r\nalabaster==0.7.10\r\nalembic==1.0.9\r\nalgopy==0.5.7\r\naltair==2.4.1\r\nanaconda-client==1.6.14\r\nanaconda-navigator==1.8.7\r\nanaconda-project==0.8.2\r\nannoy==1.15.2\r\nappdirs==1.4.3\r\narrow==0.13.1\r\nasn1crypto==0.24.0\r\nastor==0.7.1\r\nastroid==1.6.3\r\nastropy==3.0.2\r\nattrs==18.1.0\r\naudioread==2.1.6\r\nBabel==2.5.3\r\nbackcall==0.1.0\r\nbackports.shutil-get-terminal-size==1.0.0\r\nBaker==1.3\r\nbasemap==1.2.0\r\nbayesian-optimization==1.0.1\r\nbayespy==0.5.18\r\nbcolz==1.2.1\r\nbeautifulsoup4==4.6.0\r\nbiopython==1.73\r\nbitarray==0.8.1\r\nbkcharts==0.2\r\nblaze==0.11.3\r\nbleach==2.1.3\r\nblis==0.2.4\r\nblist==1.3.6\r\nbokeh==1.1.0\r\nBoruta==0.1.5\r\nboto==2.48.0\r\nboto3==1.9.134\r\nbotocore==1.12.134\r\nBottleneck==1.2.1\r\n-e git+https://github.com/SohierDane/BigQuery_Helper@8615a7f6c1663e7f2d48aa2b32c2dbcb600a440f#egg=bq_helper\r\nbranca==0.3.1\r\nbrewer2mpl==1.4.1\r\nbz2file==0.98\r\ncachetools==3.1.0\r\ncairocffi===file-.cairocffi-VERSION\r\nCairoSVG==2.3.1\r\nCartopy==0.17.0\r\ncatboost==0.14.2\r\ncategory-encoders==1.3.0\r\ncertifi==2019.3.9\r\ncesium==0.9.9\r\ncffi==1.11.5\r\nchainer==5.4.0\r\nchainercv==0.12.0\r\nchardet==3.0.4\r\ncleverhans==3.0.1\r\nClick==7.0\r\nclick-plugins==1.1.1\r\ncliff==2.14.1\r\ncligj==0.5.0\r\ncloudpickle==0.5.3\r\nclyent==1.2.2\r\ncmd2==0.9.12\r\ncmudict==0.4.2\r\ncolorama==0.3.9\r\ncolorcet==2.0.1\r\ncolorlog==4.0.2\r\ncolorlover==0.3.0\r\nconda==4.6.14\r\nconda-build==3.10.5\r\nconda-verify==2.0.0\r\nConfigArgParse==0.14.0\r\ncontextlib2==0.5.5\r\nconvertdate==2.1.3\r\nconx==3.7.7\r\ncoverage==4.5.3\r\ncryptography==2.2.2\r\ncssselect2==0.2.1\r\ncufflinks==0.15\r\nCVXcanon==0.1.1\r\ncvxpy==1.0.21\r\ncycler==0.10.0\r\ncymem==2.0.2\r\ncysignals==1.10.2\r\nCython==0.29.7\r\ncytoolz==0.9.0.1\r\ndask==1.2.0\r\ndask-glm==0.2.0\r\ndask-ml==0.12.0\r\ndask-xgboost==0.1.5\r\ndataclasses==0.6\r\ndatashader==0.7.0\r\ndatashape==0.5.4\r\ndeap==1.2.2\r\ndecorator==4.3.0\r\ndeepdish==0.3.6\r\ndefusedxml==0.6.0\r\nDelorean==1.0.0\r\ndescartes==1.1.0\r\ndill==0.2.9\r\ndipy==0.14.0\r\ndistributed==1.27.0\r\ndocopt==0.6.2\r\ndocutils==0.14\r\ndora==0.1\r\necos==2.0.5\r\nedward==1.3.5\r\neli5==0.8.2\r\nemoji==0.5.2\r\nen-core-web-lg==2.1.0\r\nen-core-web-sm==2.1.0\r\nentrypoints==0.2.3\r\nenum34==1.1.6\r\nephem==3.7.6.0\r\nessentia==2.1b5.dev532\r\net-xmlfile==1.0.1\r\nethnicolr==0.2.0\r\nfancyimpute==0.4.3\r\nfastai==1.0.51\r\nfastcache==1.0.2\r\nfasteners==0.14.1\r\nfastFM==0.2.11\r\nfastprogress==0.1.21\r\nfasttext==0.8.22\r\nfbpca==1.0\r\nfbprophet==0.4.post2\r\nfeather-format==0.4.0\r\nfeaturetools==0.7.0\r\nfilelock==3.0.4\r\nFiona==1.8.6\r\nfitter==1.0.9\r\nflake8==3.6.0\r\nflashtext==2.7\r\nFlask==1.0.2\r\nFlask-Cors==3.0.4\r\nflatbuffers==1.10\r\nfolium==0.8.3\r\nftfy==4.4.3\r\nfuncsigs==1.0.2\r\nfuncy==1.12\r\nfuture==0.17.1\r\nfuzzywuzzy==0.17.0\r\ngast==0.2.2\r\ngatspy==0.3\r\ngdbn==0.1\r\ngensim==3.7.2\r\ngeographiclib==1.49\r\nGeohash==1.0\r\ngeojson==2.4.1\r\ngeopandas==0.4.1\r\ngeoplot==0.2.4\r\ngeopy==1.19.0\r\ngeoviews==1.6.1\r\ngevent==1.3.0\r\nggplot==0.11.5\r\nglmnet-py==0.1.0b2\r\nglob2==0.6\r\ngluoncv==0.4.0.post0\r\ngluonnlp==0.6.0\r\ngmpy2==2.0.8\r\ngnumpy==0.2\r\ngoogle-api-core==1.9.0\r\ngoogle-api-python-client==1.7.8\r\ngoogle-auth==1.6.3\r\ngoogle-auth-httplib2==0.0.3\r\ngoogle-cloud-bigquery==1.11.2\r\ngoogle-cloud-core==0.29.1\r\ngoogle-resumable-media==0.3.2\r\ngoogleapis-common-protos==1.5.9\r\ngplearn==0.4.0\r\ngpxpy==1.3.5\r\ngraphviz==0.8.4\r\ngreenlet==0.4.13\r\ngrpcio==1.20.0\r\ngym==0.12.1\r\nh2o==3.24.0.2\r\nh5py==2.9.0\r\nhallucinate==0.0.1\r\nhaversine==2.0.0\r\nheamy==0.0.7\r\nheapdict==1.0.0\r\nhep-ml==0.6.0\r\nhmmlearn==0.2.1\r\nholidays==0.9.10\r\nholoviews==1.12.1\r\nhpsklearn==0.1.0\r\nhtml5lib==1.0.1\r\nhttplib2==0.12.3\r\nhumanize==0.5.1\r\nhunspell==0.5.5\r\nhusl==4.0.3\r\nhyperopt==0.1.2\r\nhypertools==0.5.1\r\nhypothesis==4.17.2\r\nibis-framework==1.0.0\r\nidna==2.6\r\nijson==2.3\r\nImageHash==4.0\r\nimageio==2.3.0\r\nimagesize==1.0.0\r\nimbalanced-learn==0.5.0.dev0\r\nimgaug==0.2.8\r\nimplicit==0.3.8\r\nipykernel==4.8.2\r\nipython==6.4.0\r\nipython-genutils==0.2.0\r\nipywidgets==7.2.1\r\niso3166==1.0\r\nisort==4.3.4\r\nisoweek==1.3.3\r\nitsdangerous==0.24\r\nJanome==0.3.8\r\njdcal==1.4\r\njedi==0.12.0\r\njieba==0.39\r\nJinja2==2.10\r\njmespath==0.9.4\r\njoblib==0.13.2\r\njsonpickle==0.9.6\r\njsonschema==2.6.0\r\njupyter==1.0.0\r\njupyter-client==5.2.3\r\njupyter-console==5.2.0\r\njupyter-core==4.4.0\r\njupyter-tensorboard==0.1.9\r\njupyterlab==0.32.1\r\njupyterlab-launcher==0.10.5\r\nKeras==2.2.4\r\nKeras-Applications==1.0.7\r\nKeras-Preprocessing==1.0.9\r\nkeras-rcnn==0.0.2\r\nkeras-resnet==0.1.0\r\nkeras-rl==0.4.2\r\nkeras-tqdm==2.0.1\r\nkiwisolver==1.0.1\r\nkmapper==1.2.0\r\nkmeans-smote==0.1.2\r\nkmodes==0.10.1\r\nknnimpute==0.1.0\r\nktext==0.34\r\nlangdetect==1.0.7\r\nlangid==1.1.6\r\nLasagne==0.2.dev1\r\nlazy-object-proxy==1.3.1\r\nlearntools==0.2.13\r\nleven==1.0.4\r\nlibrosa==0.6.3\r\nlightfm==1.15\r\nlightgbm==2.2.3\r\nlime==0.1.1.33\r\nline-profiler==2.1.2\r\nllvmlite==0.23.1\r\nlml==0.0.9\r\nlocket==0.2.0\r\nlunardate==0.2.0\r\nlxml==4.2.1\r\nlz4==2.1.2\r\nMako==1.0.9\r\nmarisa-trie==0.7.5\r\nMarkdown==3.1\r\nmarkovify==0.7.1\r\nMarkupSafe==1.0\r\nmatplotlib==3.0.3\r\nmatplotlib-venn==0.11.5\r\nmccabe==0.6.1\r\nmemory-profiler==0.55.0\r\nmissingno==0.4.1\r\nmistune==0.8.3\r\nmizani==0.5.4\r\nmkl-fft==1.0.10\r\nmkl-random==1.0.1\r\nml-metrics==0.1.4\r\nmlcrate==0.2.0\r\nmlens==0.2.3\r\nmlxtend==0.16.0.dev0\r\nmmh3==2.5.1\r\nmne==0.17.2\r\nmnist==0.2.2\r\nmock==2.0.0\r\nmonotonic==1.5\r\nmore-itertools==4.1.0\r\nmpld3==0.3\r\nmplleaflet==0.0.5\r\nmpmath==1.0.0\r\nmsgpack==0.6.1\r\nmsgpack-numpy==0.4.4.2\r\nmsgpack-python==0.5.6\r\nmultipledispatch==0.6.0\r\nmultiprocess==0.70.7\r\nmunch==2.3.2\r\nmurmurhash==1.0.0\r\nmxnet==1.4.0.post0\r\nnavigator-updater==0.2.1\r\nnbconvert==5.3.1\r\nnbformat==4.4.0\r\nnervananeon==2.6.0\r\nnetworkx==2.1\r\nnibabel==2.4.0\r\nnilearn==0.5.2\r\nnltk==3.2.4\r\nnolearn==0.6.1.dev0\r\nnose==1.3.7\r\nnotebook==5.5.0\r\nnp-utils==0.5.10.0\r\nnumba==0.38.0\r\nnumdifftools==0.9.20\r\nnumexpr==2.6.5\r\nnumpy==1.16.3\r\nnumpydoc==0.8.0\r\nnvidia-ml-py3==7.352.0\r\nodfpy==1.4.0\r\nodo==0.5.1\r\nolefile==0.45.1\r\nonnx==1.4.1\r\nopencv-python==4.1.0.25\r\nopenpyxl==2.5.3\r\noptuna==0.10.0\r\norderedmultidict==1.0\r\nortools==7.0.6546\r\nosqp==0.5.0\r\npackaging==17.1\r\npalettable==3.1.1\r\npandas==0.23.4\r\npandas-datareader==0.7.0\r\npandas-profiling==1.4.1\r\npandas-summary==0.0.6\r\npandasql==0.7.3\r\npandoc==1.0.2\r\npandocfilters==1.4.2\r\nparam==1.9.0\r\nparamnb==2.0.4\r\nparso==0.2.0\r\npartd==0.3.8\r\npath.py==11.0.1\r\npathlib2==2.3.2\r\npathos==0.2.3\r\npatsy==0.5.0\r\npbr==5.1.3\r\npdf2image==1.5.1\r\nPDPbox==0.2.0\r\npep8==1.7.1\r\npexpect==4.5.0\r\npickleshare==0.7.4\r\nPillow==5.1.0\r\npkginfo==1.4.2\r\nplac==0.9.6\r\nplotly==3.8.1\r\nplotly-express==0.1.7\r\nplotnine==0.4.0\r\npluggy==0.6.0\r\nply==3.11\r\npolyglot==16.7.4\r\nposix-ipc==1.0.4\r\npox==0.2.5\r\nppca==0.0.4\r\nppft==1.6.4.9\r\npreprocessing==0.1.13\r\npreshed==2.0.1\r\nprettytable==0.7.2\r\nprogressbar2==3.39.3\r\nprompt-toolkit==1.0.15\r\npronouncing==0.2.0\r\nprotobuf==3.7.1\r\npsutil==5.6.1\r\nptyprocess==0.5.2\r\npudb==2018.1\r\npy==1.5.3\r\npy-cpuinfo==5.0.0\r\npy-lz4framed==0.13.0\r\npy-stringmatching==0.4.1\r\npy-stringsimjoin==0.3.0\r\npyahocorasick==1.4.0\r\nPyArabic==0.6.5\r\npyarrow==0.10.0\r\npyasn1==0.4.5\r\npyasn1-modules==0.2.5\r\nPyAstronomy==0.13.0\r\npybind11==2.2.4\r\nPyBrain==0.3.3\r\npycairo==1.18.0\r\npycodestyle==2.4.0\r\npycosat==0.6.3\r\npycountry==18.12.8\r\npycparser==2.18\r\npycrypto==2.6.1\r\npyct==0.4.6\r\npycurl==7.43.0.1\r\npydash==4.7.4\r\npydicom==1.2.2\r\npydot==1.4.1\r\npyeconometrics==1.0.2\r\npyemd==0.5.1\r\npyexcel-io==0.5.17\r\npyexcel-ods==0.5.6\r\npyfasttext==0.4.6\r\npyflakes==2.0.0\r\npyflux==0.4.15\r\npyglet==1.3.2\r\nPygments==2.2.0\r\npykalman==0.9.5\r\npykoko==0.1.8\r\npyLDAvis==2.1.2\r\npylint==1.8.4\r\npymagnitude==0.1.120\r\npymc3==3.6\r\npymongo==3.8.0\r\nPympler==0.7\r\npyocr==0.6\r\npyodbc==4.0.23\r\nPyOpenGL==3.1.0\r\npyOpenSSL==18.0.0\r\npypandoc==1.4\r\npyparsing==2.2.0\r\npyPdf==1.13\r\npyperclip==1.7.0\r\nPyphen==0.9.5\r\nPyPrind==2.11.2\r\npyproj==2.1.3\r\npysal==2.0.0\r\npyshp==2.1.0\r\nPySocks==1.6.8\r\npystan==2.19.0.0\r\npytagcloud==0.3.5\r\npytesseract==0.2.6\r\npytest==3.5.1\r\npytest-arraydiff==0.2\r\npytest-astropy==0.3.0\r\npytest-cov==2.6.1\r\npytest-doctestplus==0.1.3\r\npytest-mock==1.10.4\r\npytest-openfiles==0.3.0\r\npytest-remotedata==0.2.1\r\npytext-nlp==0.1.2\r\npython-dateutil==2.6.0\r\npython-editor==1.0.4\r\npython-igraph==0.7.1.post7\r\npython-Levenshtein==0.12.0\r\npython-louvain==0.13\r\npython-utils==2.3.0\r\npytz==2018.4\r\nPyUpSet==0.1.1.post7\r\npyviz-comms==0.7.2\r\nPyWavelets==0.5.2\r\nPyYAML==3.12\r\npyzmq==17.0.0\r\nQtAwesome==0.4.4\r\nqtconsole==4.3.1\r\nQtPy==1.4.1\r\nraccoon==2.1.5\r\nrandomgen==1.16.4\r\nray==0.6.6\r\nredis==3.2.1\r\nregex==2019.4.14\r\nrequests==2.21.0\r\nresampy==0.2.1\r\nretrying==1.3.3\r\nrevrand==0.6.5\r\nrf-perm-feat-import==0.1\r\nrgf-python==3.5.0\r\nrope==0.10.7\r\nrsa==4.0\r\nruamel-yaml==0.15.35\r\ns2sphere==0.2.5\r\ns3fs==0.2.1\r\ns3transfer==0.2.0\r\nsacred==0.7.4\r\nscattertext==0.0.2.48\r\nscikit-image==0.15.0\r\nscikit-learn==0.20.3\r\nscikit-multilearn==0.2.0\r\nscikit-optimize==0.5.2\r\nscikit-plot==0.3.7\r\nscikit-surprise==1.0.6\r\nscipy==1.1.0\r\nscs==2.1.0\r\nseaborn==0.9.0\r\nSend2Trash==1.5.0\r\nsentencepiece==0.1.82\r\nsetuptools-git==1.2\r\nshap==0.28.5\r\nShapely==1.6.4.post2\r\nsimplegeneric==0.8.1\r\nSimpleITK==1.2.0\r\nsingledispatch==3.4.0.3\r\nsix==1.12.0\r\nsklearn==0.0\r\nsklearn-contrib-lightning==0.5.0\r\nsklearn-contrib-py-earth==0.1.0\r\nsklearn-pandas==1.8.0\r\nsmart-open==1.8.2\r\nsmhasher==0.150.1\r\nsnowballstemmer==1.2.1\r\nsortedcollections==0.6.1\r\nsortedcontainers==1.5.10\r\nspacy==2.1.3\r\nspectral==0.19\r\nspeedml==0.9.3\r\nSphinx==1.7.4\r\nsphinx-rtd-theme==0.2.4\r\nsphinxcontrib-websupport==1.0.1\r\nspyder==3.2.8\r\nSQLAlchemy==1.2.7\r\nsquarify==0.4.2\r\nsrsly==0.0.5\r\nstatsmodels==0.9.0\r\nstemming==1.0.1\r\nstevedore==1.30.1\r\nstop-words==2018.7.23\r\nstopit==1.1.2\r\nsvgwrite==1.2.1\r\nsympy==1.1.1\r\ntables==3.5.1\r\ntabulate==0.8.3\r\ntblib==1.3.2\r\ntensorboard==1.13.1\r\ntensorboardX==1.6\r\ntensorflow==1.13.1\r\ntensorflow-estimator==1.13.0\r\ntensorflow-hub==0.4.0\r\ntensorflow-probability==0.6.0\r\ntensorforce==0.4.3\r\ntensorpack==0.9.4\r\ntermcolor==1.1.0\r\nterminado==0.8.1\r\nterminalplot==0.2.6\r\ntestpath==0.3.1\r\ntextacy==0.6.2\r\ntextblob==0.15.3\r\ntflearn==0.3.2\r\nTheano==1.0.4+10.g9feed7868\r\nthinc==7.0.4\r\ntifffile==2019.3.18\r\ntinycss2==1.0.2\r\ntoolz==0.9.0\r\ntorch==1.0.1.post2\r\ntorchaudio==0.2\r\ntorchtext==0.3.1\r\ntorchvision==0.2.2\r\ntornado==5.0.2\r\nTPOT==0.10.1\r\ntqdm==4.31.1\r\ntrackml==0.1.12\r\ntraitlets==4.3.2\r\ntrueskill==0.4.5\r\ntsfresh==0.11.2\r\ntyping==3.6.4\r\ntyping-extensions==3.7.2\r\ntzlocal==1.5.1\r\numap-learn==0.3.8\r\nunicodecsv==0.14.1\r\nUnidecode==1.0.23\r\nupdate-checker==0.16\r\nuritemplate==3.0.0\r\nurllib3==1.22\r\nurwid==2.0.1\r\nvecstack==0.3.0\r\nvega3==0.13.0\r\nvida==0.3\r\nvisvis==1.11.2\r\nvowpalwabbit==8.5.0\r\nvtk==8.1.2\r\nWand==0.5.3\r\nwasabi==0.2.1\r\nwavio==0.0.4\r\nwcwidth==0.1.7\r\nwebencodings==0.5.1\r\nwebsocket-client==0.56.0\r\nWerkzeug==0.14.1\r\nwfdb==2.2.1\r\nwidgetsnbextension==3.2.1\r\nwikipedia==1.4.0\r\nWordbatch==1.3.8\r\nwordcloud==1.5.0\r\nwordsegment==1.3.1\r\nwrapt==1.10.11\r\nxarray==0.12.1\r\nxgboost==0.82\r\nxlrd==1.1.0\r\nXlsxWriter==1.0.4\r\nxlwt==1.3.0\r\nxvfbwrapper==0.2.9\r\nxxhash==1.3.0\r\nyellowbrick==0.9.1\r\nzict==0.1.3\r\n","name":"stdout"}]},{"metadata":{"nbpresent":{"id":"f0d29da8-3e35-4378-ae18-6f30e82ee1e2"},"trusted":true},"cell_type":"code","source":"# Using nltk (Natural Language Tool Kit) library \nfrom nltk.corpus import stopwords\nprint(stopwords.words(\"english\"))","execution_count":4,"outputs":[{"output_type":"stream","text":"['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n","name":"stdout"}]},{"metadata":{"nbpresent":{"id":"6cf2abc7-8af4-49a5-9501-5afcf04b3f28"},"trusted":true},"cell_type":"code","source":"print(stopwords.words(\"portuguese\"))","execution_count":5,"outputs":[{"output_type":"stream","text":"['de', 'a', 'o', 'que', 'e', 'do', 'da', 'em', 'um', 'para', 'com', 'não', 'uma', 'os', 'no', 'se', 'na', 'por', 'mais', 'as', 'dos', 'como', 'mas', 'ao', 'ele', 'das', 'à', 'seu', 'sua', 'ou', 'quando', 'muito', 'nos', 'já', 'eu', 'também', 'só', 'pelo', 'pela', 'até', 'isso', 'ela', 'entre', 'depois', 'sem', 'mesmo', 'aos', 'seus', 'quem', 'nas', 'me', 'esse', 'eles', 'você', 'essa', 'num', 'nem', 'suas', 'meu', 'às', 'minha', 'numa', 'pelos', 'elas', 'qual', 'nós', 'lhe', 'deles', 'essas', 'esses', 'pelas', 'este', 'dele', 'tu', 'te', 'vocês', 'vos', 'lhes', 'meus', 'minhas', 'teu', 'tua', 'teus', 'tuas', 'nosso', 'nossa', 'nossos', 'nossas', 'dela', 'delas', 'esta', 'estes', 'estas', 'aquele', 'aquela', 'aqueles', 'aquelas', 'isto', 'aquilo', 'estou', 'está', 'estamos', 'estão', 'estive', 'esteve', 'estivemos', 'estiveram', 'estava', 'estávamos', 'estavam', 'estivera', 'estivéramos', 'esteja', 'estejamos', 'estejam', 'estivesse', 'estivéssemos', 'estivessem', 'estiver', 'estivermos', 'estiverem', 'hei', 'há', 'havemos', 'hão', 'houve', 'houvemos', 'houveram', 'houvera', 'houvéramos', 'haja', 'hajamos', 'hajam', 'houvesse', 'houvéssemos', 'houvessem', 'houver', 'houvermos', 'houverem', 'houverei', 'houverá', 'houveremos', 'houverão', 'houveria', 'houveríamos', 'houveriam', 'sou', 'somos', 'são', 'era', 'éramos', 'eram', 'fui', 'foi', 'fomos', 'foram', 'fora', 'fôramos', 'seja', 'sejamos', 'sejam', 'fosse', 'fôssemos', 'fossem', 'for', 'formos', 'forem', 'serei', 'será', 'seremos', 'serão', 'seria', 'seríamos', 'seriam', 'tenho', 'tem', 'temos', 'tém', 'tinha', 'tínhamos', 'tinham', 'tive', 'teve', 'tivemos', 'tiveram', 'tivera', 'tivéramos', 'tenha', 'tenhamos', 'tenham', 'tivesse', 'tivéssemos', 'tivessem', 'tiver', 'tivermos', 'tiverem', 'terei', 'terá', 'teremos', 'terão', 'teria', 'teríamos', 'teriam']\n","name":"stdout"}]},{"metadata":{"nbpresent":{"id":"d44b3d6b-b173-4d78-b568-8c79cea8ee83"},"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport pickle","execution_count":6,"outputs":[]},{"metadata":{"nbpresent":{"id":"aa58e0ff-5e84-4d5d-a1d7-d93c0e3012c1"},"trusted":true},"cell_type":"code","source":"# Toy dataset\ntext = \"I want chocolate, preferably dark chocolate\"\ntext2 = \"I need chocolate because if I do not have chocolate I will cry\"\ntext3 = \"please give me chocolate... PLEASE!!!\"\ntext_list = [text, text2, text3]\ntext_list","execution_count":7,"outputs":[{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"['I want chocolate, preferably dark chocolate',\n 'I need chocolate because if I do not have chocolate I will cry',\n 'please give me chocolate... PLEASE!!!']"},"metadata":{}}]},{"metadata":{"nbpresent":{"id":"06b707b3-85f5-4fc0-abbc-6eff70e898fb"}},"cell_type":"markdown","source":"### Preprocessing\nSome common preprocessing tasks\n* Stemming/lemmatizing\n* Removing HTML markup\n* Removing non-letters\n* Converting words to lower case\n* Removing stopwords"},{"metadata":{"nbpresent":{"id":"e945fea6-08db-4234-a1b9-3ae224351dbe"},"trusted":true},"cell_type":"code","source":"from bs4 import BeautifulSoup\nimport re\nfrom nltk.corpus import stopwords\n\nstop_words = set(stopwords.words('english'))\n\nclass StringPreprocessor():\n    \"\"\"\n    Class to preprocess a string\n    \"\"\"\n    def __init__(self, stop_words = ['english'], remove_non_letters = True, lowercase = True,\n                 remove_html = True):\n        self.stop_words = stop_words\n        self.remove_non_letters = remove_non_letters\n        self.lowercase = lowercase\n        self.remove_html = remove_html\n        \n    def transform(self, text):\n        if self.remove_html:\n            # 1. Remove HTML markup\n            text = BeautifulSoup(text).get_text()\n    \n        if self.remove_non_letters:\n            # 2. Remove non-letters\n            text = re.sub(\"[^a-zA-Z]\",\" \", text)\n    \n        if self.lowercase:\n            # 3. Convert words to lower case \n            text = text.lower()\n     \n        if stop_words is not None:\n            # 4. Remove Stopwords\n            text_list = [word for word in text.split() if word not in stop_words]\n            text = \" \".join(text_list)\n    \n        # 5. Return the processed string\n        return(text)","execution_count":8,"outputs":[]},{"metadata":{"nbpresent":{"id":"37100d4d-e824-4d35-b5cc-d9769b64e714"},"trusted":true},"cell_type":"code","source":"# Use the StringPreprocessing class to clean the sentences \nprocessor = StringPreprocessor()\nclean_text_list = [processor.transform(text) for text in text_list]\nfor raw, clean in zip(text_list, clean_text_list):\n    print(\"{} --> {}\".format(raw, clean))","execution_count":9,"outputs":[{"output_type":"stream","text":"I want chocolate, preferably dark chocolate --> want chocolate preferably dark chocolate\nI need chocolate because if I do not have chocolate I will cry --> need chocolate chocolate cry\nplease give me chocolate... PLEASE!!! --> please give chocolate please\n","name":"stdout"}]},{"metadata":{"nbpresent":{"id":"6208d14a-d786-4be7-813c-da84ee8f2183"}},"cell_type":"markdown","source":"#### Stemming \n* For grammatical reasons, documents use different forms of a word\n* Goal of stemming and lemmatizing is to reduce inflectional forms of a word to a common base form\n    - take the root stem of the word\n    - Operates on a single word\n    \n"},{"metadata":{"nbpresent":{"id":"3694fedc-68af-4785-a863-7da3e6ca8aea"},"trusted":true},"cell_type":"code","source":"from nltk.stem import PorterStemmer\nfrom nltk.tokenize import word_tokenize\n\nps = PorterStemmer()\nfor word in [\"ride\", \"riding\", \"rode\", \"chocolates\", \"cacti\", \"laziness\"]:\n    print(\"{} --> {}\".format(word, ps.stem(word)))","execution_count":10,"outputs":[{"output_type":"stream","text":"ride --> ride\nriding --> ride\nrode --> rode\nchocolates --> chocol\ncacti --> cacti\nlaziness --> lazi\n","name":"stdout"}]},{"metadata":{"nbpresent":{"id":"aae7106f-82d0-47ca-a63e-519991a33711"}},"cell_type":"markdown","source":"#### Lemmatizing\n* Lemma - dictionary form\n* Unlike stemming, lemmatisation depends on correctly identifying the intended part of speech and meaning of a word in a sentence\n* Result is a real word"},{"metadata":{"nbpresent":{"id":"2831a31c-df75-44c1-96d3-4004f3f02d84"},"trusted":true},"cell_type":"code","source":"from nltk.stem import WordNetLemmatizer\nlemmatizer = WordNetLemmatizer()\n\nfor word in [\"ride\", \"riding\", \"rode\"]: \n    print(\"{} --> {}\".format(word, lemmatizer.lemmatize(word, pos = \"v\"))) #Pos indicates part of speech\n    \nfor word in [\"chocolates\", \"cacti\"]:\n    print(\"{} --> {}\".format(word, lemmatizer.lemmatize(word, pos = \"n\")))# default is noun (n)\n    \nprint(\"{} --> {}\".format(\"laziness\", lemmatizer.lemmatize(\"laziness\", pos = \"a\")))# adjectives","execution_count":11,"outputs":[{"output_type":"stream","text":"ride --> ride\nriding --> rid\nrode --> ride\nchocolates --> chocolate\ncacti --> cactus\nlaziness --> laziness\n","name":"stdout"}]},{"metadata":{"nbpresent":{"id":"6d947106-aeac-4203-a15f-f91512f3e920"}},"cell_type":"markdown","source":"## Feature Extraction\n\n### Bag of Words\n* A simple representation of word vectors\n* Text is represented as the number of occurencies of each word\n* Disregards grammar and word order\n\nThis model can be implemented in Python with Sklearn's [CountVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) class. "},{"metadata":{"nbpresent":{"id":"70f63fd2-c87b-407c-9061-c231a7c21a93"},"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\n# Initiate a CountVectorizer object\nvectorizer = CountVectorizer()\nprint(vectorizer)","execution_count":12,"outputs":[{"output_type":"stream","text":"CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n        tokenizer=None, vocabulary=None)\n","name":"stdout"}]},{"metadata":{"nbpresent":{"id":"9e982452-afaa-4149-af68-26f25f10248f"},"trusted":true},"cell_type":"code","source":"# Create a dictionary from the text\nvectorizer.fit(clean_text_list)\nprint(clean_text_list, \"\\n\")\nprint(vectorizer.get_feature_names())","execution_count":13,"outputs":[{"output_type":"stream","text":"['want chocolate preferably dark chocolate', 'need chocolate chocolate cry', 'please give chocolate please'] \n\n['chocolate', 'cry', 'dark', 'give', 'need', 'please', 'preferably', 'want']\n","name":"stdout"}]},{"metadata":{"nbpresent":{"id":"9b84f42c-c9d8-4a4f-8cba-0a8ee9333385"},"trusted":true},"cell_type":"code","source":"# Transform the train text into a document term matrix\ntext_dtm = vectorizer.transform(clean_text_list)\nprint(type(text_dtm))\nprint(text_dtm)","execution_count":14,"outputs":[{"output_type":"stream","text":"<class 'scipy.sparse.csr.csr_matrix'>\n  (0, 0)\t2\n  (0, 2)\t1\n  (0, 6)\t1\n  (0, 7)\t1\n  (1, 0)\t2\n  (1, 1)\t1\n  (1, 4)\t1\n  (2, 0)\t1\n  (2, 3)\t1\n  (2, 5)\t2\n","name":"stdout"}]},{"metadata":{"nbpresent":{"id":"9dc7cf76-9be5-48a2-a3c3-13be9d8cf5f3"},"trusted":true},"cell_type":"code","source":"# Create a dense matrix from the sparse matrix\ndense_mat = text_dtm.toarray()\npd.DataFrame(dense_mat, columns = vectorizer.get_feature_names())","execution_count":15,"outputs":[{"output_type":"execute_result","execution_count":15,"data":{"text/plain":"   chocolate  cry  dark  give  need  please  preferably  want\n0          2    0     1     0     0       0           1     1\n1          2    1     0     0     1       0           0     0\n2          1    0     0     1     0       2           0     0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>chocolate</th>\n      <th>cry</th>\n      <th>dark</th>\n      <th>give</th>\n      <th>need</th>\n      <th>please</th>\n      <th>preferably</th>\n      <th>want</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"nbpresent":{"id":"847d0b76-5ea7-42b4-b65e-7424bf2f3e65"}},"cell_type":"markdown","source":"Using this approach features and samples are defined as follows:\n* Feature - Each Individual token occurence frequency\n* Sample (or document) - The vector of all features for a given document\n\nA corpus of documents can be represented by a matrix whith a single row per document and a single column per token that occurrs in the corpus. \n\nIn order to make a prediction, it is necessary that the new observation has the same features as the trainning observation\n* Both in number and in meaning\n\nLet's consider the Wikipedia page for \"chocolate\""},{"metadata":{"nbpresent":{"id":"a1adf755-36f3-42b7-b8e4-85d285e8287a"},"trusted":true},"cell_type":"code","source":"# Using the model to transform new data\nimport wikipedia\n\ndef get_wikipedia_page(page_name):\n    try:\n        page =  wikipedia.page(page_name).content\n        with open(os.path.join(*WORK_DIR, \"wikipediaPage.pkl\"), \"wb\") as fp:\n            pickle.dump(page, fp)\n    except Exception:\n        with open(os.path.join(*WORK_DIR, \"wikipediaPage.pkl\"), \"rb\") as fp:\n            page = pickle.load(fp)\n    return page\n\nwikipedia_chocolate = get_wikipedia_page(\"chocolate\")\n\n# Transform documents using the vectorizer\ntest_dtm = vectorizer.transform([wikipedia_chocolate])\n\n# Output a pandas dataframe\nvocab_df = pd.DataFrame(test_dtm.toarray(), columns = vectorizer.get_feature_names())\nvocab_df","execution_count":16,"outputs":[{"output_type":"execute_result","execution_count":16,"data":{"text/plain":"   chocolate  cry  dark  give  need  please  preferably  want\n0        301    0    18     1     2       0           0     0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>chocolate</th>\n      <th>cry</th>\n      <th>dark</th>\n      <th>give</th>\n      <th>need</th>\n      <th>please</th>\n      <th>preferably</th>\n      <th>want</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>301</td>\n      <td>0</td>\n      <td>18</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"nbpresent":{"id":"83f43e46-cbf4-488a-b113-c7d8e387883f"}},"cell_type":"markdown","source":"### N-gram Model¶\n\nThis model preserves some local ordering information\n* Considers N tokens in a row\n* The features are the resulting N-grams\n"},{"metadata":{"nbpresent":{"id":"dc00de7a-3ed5-4caa-95be-1fd7d583ae4e"},"trusted":true},"cell_type":"code","source":"from nltk.util import ngrams\nfrom nltk import word_tokenize\n\ntext_list_words = word_tokenize(\" \".join(clean_text_list))[:10]\ntext_list_words","execution_count":17,"outputs":[{"output_type":"execute_result","execution_count":17,"data":{"text/plain":"['want',\n 'chocolate',\n 'preferably',\n 'dark',\n 'chocolate',\n 'need',\n 'chocolate',\n 'chocolate',\n 'cry',\n 'please']"},"metadata":{}}]},{"metadata":{"nbpresent":{"id":"ccddf0ad-98b2-46cd-af54-874459e6d901"},"trusted":true},"cell_type":"code","source":"# Unigrams\nlist(ngrams(text_list_words, 1))","execution_count":18,"outputs":[{"output_type":"execute_result","execution_count":18,"data":{"text/plain":"[('want',),\n ('chocolate',),\n ('preferably',),\n ('dark',),\n ('chocolate',),\n ('need',),\n ('chocolate',),\n ('chocolate',),\n ('cry',),\n ('please',)]"},"metadata":{}}]},{"metadata":{"nbpresent":{"id":"cf0fd429-eee7-459a-9f31-6c9e998ddb3e"},"trusted":true},"cell_type":"code","source":"# Bigrams\nlist(ngrams(text_list_words, 2))","execution_count":19,"outputs":[{"output_type":"execute_result","execution_count":19,"data":{"text/plain":"[('want', 'chocolate'),\n ('chocolate', 'preferably'),\n ('preferably', 'dark'),\n ('dark', 'chocolate'),\n ('chocolate', 'need'),\n ('need', 'chocolate'),\n ('chocolate', 'chocolate'),\n ('chocolate', 'cry'),\n ('cry', 'please')]"},"metadata":{}}]},{"metadata":{"nbpresent":{"id":"f97e57ff-9ea4-463c-81c3-79e12fbbbd0d"},"trusted":true},"cell_type":"code","source":"# Trigrams\nlist(ngrams(text_list_words, 3))","execution_count":20,"outputs":[{"output_type":"execute_result","execution_count":20,"data":{"text/plain":"[('want', 'chocolate', 'preferably'),\n ('chocolate', 'preferably', 'dark'),\n ('preferably', 'dark', 'chocolate'),\n ('dark', 'chocolate', 'need'),\n ('chocolate', 'need', 'chocolate'),\n ('need', 'chocolate', 'chocolate'),\n ('chocolate', 'chocolate', 'cry'),\n ('chocolate', 'cry', 'please')]"},"metadata":{}}]},{"metadata":{"nbpresent":{"id":"1d3301e1-50d3-4332-a27b-9b96eff37c5c"},"trusted":true},"cell_type":"code","source":"# Create a bigram model (N=2) using CountVectorizer's ngram_range\n# ngram_range : tuple(min_N, max_N)\n\nbigram_vectorizer = CountVectorizer(ngram_range = (2,2))\nbigrams = bigram_vectorizer.fit_transform(clean_text_list)\npd.DataFrame(bigrams.toarray(),\n             columns = bigram_vectorizer.get_feature_names())","execution_count":21,"outputs":[{"output_type":"execute_result","execution_count":21,"data":{"text/plain":"   chocolate chocolate       ...        want chocolate\n0                    0       ...                     1\n1                    1       ...                     0\n2                    0       ...                     0\n\n[3 rows x 10 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>chocolate chocolate</th>\n      <th>chocolate cry</th>\n      <th>chocolate please</th>\n      <th>chocolate preferably</th>\n      <th>dark chocolate</th>\n      <th>give chocolate</th>\n      <th>need chocolate</th>\n      <th>please give</th>\n      <th>preferably dark</th>\n      <th>want chocolate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"nbpresent":{"id":"f2de9d29-5b52-43fd-b594-5a60a52e20f4"},"trusted":true},"cell_type":"code","source":"from collections import Counter, OrderedDict\n\ndef build_vocabulary(text_):\n    vocabulary = Counter()\n\n    for doc in text_:\n        words = doc.split()\n        vocabulary.update(words)\n    \n    return OrderedDict(vocabulary.most_common())\n\n# turn into a list of tuples and get the first 10 items\ntop_words = list(build_vocabulary(clean_text_list).items())\ntop_words[:10]","execution_count":22,"outputs":[{"output_type":"execute_result","execution_count":22,"data":{"text/plain":"[('chocolate', 5),\n ('please', 2),\n ('want', 1),\n ('preferably', 1),\n ('dark', 1),\n ('need', 1),\n ('cry', 1),\n ('give', 1)]"},"metadata":{}}]},{"metadata":{"nbpresent":{"id":"1e3c9dd9-687a-4af3-a8a5-f44d8154bebe"},"trusted":true},"cell_type":"code","source":"top_words = list(build_vocabulary(wikipedia_chocolate.split()).items())\ntop_words[:10]","execution_count":23,"outputs":[{"output_type":"execute_result","execution_count":23,"data":{"text/plain":"[('the', 332),\n ('of', 238),\n ('and', 220),\n ('chocolate', 182),\n ('to', 150),\n ('in', 142),\n ('a', 130),\n ('is', 118),\n ('cocoa', 79),\n ('as', 78)]"},"metadata":{}}]},{"metadata":{"collapsed":true,"nbpresent":{"id":"ce35f8d3-b9f6-4887-9004-c94acf0f3f11"}},"cell_type":"markdown","source":"## TF-IDF\nTerm Frequency - Inverse Document Frequency\n* Numerical statistic reflecting how important a token is to a document\n* Often used as weighting factor\n    * Information retrieval\n    * Text mining\n    \nTerm Frequency = Bag of Words\n\nInverse Document Frequency \n* Measure of how much information a term provides\n    * Whether a term is common or rare across documents \n    \n* Logarithmically scaled inverse fraction of documents that contain the token\n<img src=\"../input/idf.png\" alt=\"text\" width=\"250px\"/>\n\nwhere\n* nd : number of documents in the corpus \n* df(d,t) : the number of documents d where token t appears \n\nVariations  \n* Scikit Learn's\n<img src=\"../input/idf2.png\" alt=\"text\" width=\"300px\"/>\n* [Other variations of tf-idf](https://en.wikipedia.org/wiki/Tf%E2%80%93idf)\n \n\nTf-Idf is the product of term frequency tf(t,d) and inverse document frequency\n\n<img src=\"../input/tfidf.png\" alt=\"text\" width=\"300px\"/>\n * Can be easily built using the [TdfidfVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) class from sklearn\n"},{"metadata":{"nbpresent":{"id":"6de59e58-b4eb-471e-b5f8-fac91dece4b6"},"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\n\n# Instantiate a tf-idf vectorizer class\ntf_idf = TfidfVectorizer(norm = None)\ntf_idf","execution_count":24,"outputs":[{"output_type":"execute_result","execution_count":24,"data":{"text/plain":"TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n        ngram_range=(1, 1), norm=None, preprocessor=None, smooth_idf=True,\n        stop_words=None, strip_accents=None, sublinear_tf=False,\n        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n        vocabulary=None)"},"metadata":{}}]},{"metadata":{"nbpresent":{"id":"1f5daca7-706f-4b52-a6c1-664f1cc5eeff"},"trusted":true},"cell_type":"code","source":"# learn the vocabulary from the corpus of documents\nfitted = tf_idf.fit(text_list)\nprint(fitted.get_feature_names())","execution_count":25,"outputs":[{"output_type":"stream","text":"['because', 'chocolate', 'cry', 'dark', 'do', 'give', 'have', 'if', 'me', 'need', 'not', 'please', 'preferably', 'want', 'will']\n","name":"stdout"}]},{"metadata":{"nbpresent":{"id":"4e43dedd-9250-445e-8868-47b0aa86de0f"},"trusted":true},"cell_type":"code","source":"# transform the documents using the learned vocabulary\ntransformed = tf_idf.transform(text_list)\npd.DataFrame(transformed.toarray(), columns = fitted.get_feature_names())","execution_count":26,"outputs":[{"output_type":"execute_result","execution_count":26,"data":{"text/plain":"    because  chocolate       cry    ...     preferably      want      will\n0  0.000000        2.0  0.000000    ...       1.693147  1.693147  0.000000\n1  1.693147        2.0  1.693147    ...       0.000000  0.000000  1.693147\n2  0.000000        1.0  0.000000    ...       0.000000  0.000000  0.000000\n\n[3 rows x 15 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>because</th>\n      <th>chocolate</th>\n      <th>cry</th>\n      <th>dark</th>\n      <th>do</th>\n      <th>give</th>\n      <th>have</th>\n      <th>if</th>\n      <th>me</th>\n      <th>need</th>\n      <th>not</th>\n      <th>please</th>\n      <th>preferably</th>\n      <th>want</th>\n      <th>will</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.000000</td>\n      <td>2.0</td>\n      <td>0.000000</td>\n      <td>1.693147</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.693147</td>\n      <td>1.693147</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.693147</td>\n      <td>2.0</td>\n      <td>1.693147</td>\n      <td>0.000000</td>\n      <td>1.693147</td>\n      <td>0.000000</td>\n      <td>1.693147</td>\n      <td>1.693147</td>\n      <td>0.000000</td>\n      <td>1.693147</td>\n      <td>1.693147</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.693147</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.000000</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.693147</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.693147</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>3.386294</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"nbpresent":{"id":"373f0e78-c72d-4019-9763-2bd7313c331b"},"trusted":true},"cell_type":"code","source":"# vectorize the test documents\ntest = tf_idf.transform([wikipedia_chocolate])\npd.DataFrame(test.toarray(), columns = fitted.get_feature_names())","execution_count":27,"outputs":[{"output_type":"execute_result","execution_count":27,"data":{"text/plain":"    because  chocolate  cry    ...      preferably  want       will\n0  11.85203      301.0  0.0    ...             0.0   0.0  15.238325\n\n[1 rows x 15 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>because</th>\n      <th>chocolate</th>\n      <th>cry</th>\n      <th>dark</th>\n      <th>do</th>\n      <th>give</th>\n      <th>have</th>\n      <th>if</th>\n      <th>me</th>\n      <th>need</th>\n      <th>not</th>\n      <th>please</th>\n      <th>preferably</th>\n      <th>want</th>\n      <th>will</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>11.85203</td>\n      <td>301.0</td>\n      <td>0.0</td>\n      <td>30.476649</td>\n      <td>1.693147</td>\n      <td>1.693147</td>\n      <td>42.32868</td>\n      <td>18.624619</td>\n      <td>0.0</td>\n      <td>3.386294</td>\n      <td>23.704061</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>15.238325</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"nbpresent":{"id":"e932ab80-f9dd-45a6-9708-1680936fa42f"}},"cell_type":"markdown","source":"## Word Embeddings\n* Word vectors with arbitrary size\n* \"You shall know a word by the company it keeps\"- John Firth\n\n\n### Word2Vec \nGeneric name for a group models used to produce word embeddings\n* Two-layer [neural networks](https://en.wikipedia.org/wiki/Neural_network) trained to reconstruct linguistic contexts of words\n<img src = \"deep-neural-networks.png\" alt=\"50px\" width=\"300\"/>\n* Resulting word vectors are positioned in the vector space such that the words wich share similar contexts are closer\n<img src = \"../input/word2vec_graph2.png\"width=\"500\">\n\n* Two types of Word2Vec\n    - **CBOW** (continuous bag of words): context words are input words, predicts middle word\n    - **Skip-gram**: context words are input words, predicts middle word   \n    \n<img src=\"../input/word2vec.png\" width=\"400\">\n\n* Algorithm relies on the broader context of the sentence \n    * To **train Word2Vec** it is better **not to remove stop words**\n    \nSince Word2Vec requires meaningfull context in order to train itself, we need a more informative corpus"},{"metadata":{"nbpresent":{"id":"18487037-6826-4cb8-a4d2-ebc2cdd92c85"}},"cell_type":"markdown","source":"#### IMDB Movie Review Dataset\nA dataset containing various IMDB movie reviews\n* Some labeled as positive or negative"},{"metadata":{"nbpresent":{"id":"b6cad708-c3c3-48db-a476-875b41617231"},"trusted":true},"cell_type":"code","source":"# Read data from files \nlabeled = pd.read_csv(os.path.join(*DATA_DIR, \"labeledTrainData.tsv\"), header=0,\n                                   delimiter = \"\\t\", quoting=3 )\nunlabeled1 = pd.read_csv(os.path.join(*DATA_DIR,\"unlabeledTrainData.tsv\"), header=0,\n                                      delimiter=\"\\t\", quoting=3 )\nunlabeled2 = pd.read_csv(os.path.join(*DATA_DIR,\"testData.tsv\"), header=0,\n                                      delimiter=\"\\t\", quoting=3 )\n\n# Verify the number of reviews that were read (100,000 in total)\nprint( \"Read %d labeled reviews, %d unlabeled reviews, \" \\\n       % (labeled[\"review\"].size, unlabeled1[\"review\"].size + unlabeled2[\"review\"].size ))","execution_count":28,"outputs":[{"output_type":"stream","text":"Read 25000 labeled reviews, 75000 unlabeled reviews, \n","name":"stdout"}]},{"metadata":{"nbpresent":{"id":"d6d407e8-d0c0-45e4-81c1-1570516a596a"},"trusted":true},"cell_type":"code","source":"labeled.head()","execution_count":29,"outputs":[{"output_type":"execute_result","execution_count":29,"data":{"text/plain":"         id                        ...                                                                     review\n0  \"5814_8\"                        ...                          \"With all this stuff going down at the moment ...\n1  \"2381_9\"                        ...                          \"\\\"The Classic War of the Worlds\\\" by Timothy ...\n2  \"7759_3\"                        ...                          \"The film starts with a manager (Nicholas Bell...\n3  \"3630_4\"                        ...                          \"It must be assumed that those who praised thi...\n4  \"9495_8\"                        ...                          \"Superbly trashy and wondrously unpretentious ...\n\n[5 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>sentiment</th>\n      <th>review</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>\"5814_8\"</td>\n      <td>1</td>\n      <td>\"With all this stuff going down at the moment ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>\"2381_9\"</td>\n      <td>1</td>\n      <td>\"\\\"The Classic War of the Worlds\\\" by Timothy ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>\"7759_3\"</td>\n      <td>0</td>\n      <td>\"The film starts with a manager (Nicholas Bell...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>\"3630_4\"</td>\n      <td>0</td>\n      <td>\"It must be assumed that those who praised thi...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>\"9495_8\"</td>\n      <td>1</td>\n      <td>\"Superbly trashy and wondrously unpretentious ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"nbpresent":{"id":"54ca3693-d71d-4b3f-be50-961fa175d14f"},"trusted":true},"cell_type":"code","source":"unlabeled1.head()","execution_count":30,"outputs":[{"output_type":"execute_result","execution_count":30,"data":{"text/plain":"          id                                             review\n0   \"9999_0\"  \"Watching Time Chasers, it obvious that it was...\n1  \"45057_0\"  \"I saw this film about 20 years ago and rememb...\n2  \"15561_0\"  \"Minor Spoilers<br /><br />In New York, Joan B...\n3   \"7161_0\"  \"I went to see this film with a great deal of ...\n4  \"43971_0\"  \"Yes, I agree with everyone on this site this ...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>review</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>\"9999_0\"</td>\n      <td>\"Watching Time Chasers, it obvious that it was...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>\"45057_0\"</td>\n      <td>\"I saw this film about 20 years ago and rememb...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>\"15561_0\"</td>\n      <td>\"Minor Spoilers&lt;br /&gt;&lt;br /&gt;In New York, Joan B...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>\"7161_0\"</td>\n      <td>\"I went to see this film with a great deal of ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>\"43971_0\"</td>\n      <td>\"Yes, I agree with everyone on this site this ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"nbpresent":{"id":"d0a3c5f7-33c8-4a4d-bc14-9f63ee102978"},"trusted":true},"cell_type":"code","source":"processor = StringPreprocessor(stop_words = None)\n    \ndef review_to_wordlist(review):\n    # Function to convert a document to a sequence of clean words\n    # Returns a list of words.\n    return processor.transform(review).split()","execution_count":33,"outputs":[]},{"metadata":{"collapsed":true,"nbpresent":{"id":"ea0a8ed0-3be2-4cb8-b7a0-c0c987157735"}},"cell_type":"markdown","source":"Word2Vec expects single sentences, each one as a list of words. In other words, the input format is a list of lists."},{"metadata":{"nbpresent":{"id":"d44422b6-625a-4ae8-a655-293a7238e7bd"},"trusted":true},"cell_type":"code","source":"from nltk import sent_tokenize\n\nraw_sentences = []\nparsed_sentences = []\n\nfor review in unlabeled1['review']:\n    for raw_sent in sent_tokenize(review):\n        if len(raw_sent) > 0:\n            parsed_sentences.append(review_to_wordlist(raw_sent))\n\nfor review in unlabeled2['review']:\n    for raw_sent in sent_tokenize(review):\n        if len(raw_sent) > 0:\n            parsed_sentences.append(review_to_wordlist(raw_sent))\n\nprint(len(parsed_sentences))\nprint(parsed_sentences[0])","execution_count":34,"outputs":[{"output_type":"stream","text":"790387\n['watching', 'time', 'chasers', 'obvious', 'made', 'bunch', 'friends']\n","name":"stdout"}]},{"metadata":{"nbpresent":{"id":"b4eefc2d-00d3-4368-934d-656a70e9f70b"},"trusted":true},"cell_type":"code","source":"import logging\nfrom gensim.models.word2vec import Word2Vec\nfrom gensim.models import word2vec\n\n# Parameters\nnum_features = 300    # Word vector dimensionality\nmin_word_count = 1    # Minimum word count\nnum_workers = 4       # Number of threads to run in parallel\ncontext = 10          # Context window size\ndownsampling = 1e-3   # Downsample setting for frequent words\n\n# Initialize and train model\n\nprint(\"Training model...\")\nmodel = word2vec.Word2Vec(parsed_sentences, workers = num_workers,\n                         size = num_features, min_count = min_word_count,\n                         window = context, sample = downsampling)\n\n# If you dont plan to train the model any further, calling\n# init_sims will make the model much more memory-efficient\nmodel.init_sims(replace = True)\n\n# Save the model for later use\nmodel_name = os.path.join(*WORK_DIR, \"300features_40minwords_10context\")\n#model.save(model_name)","execution_count":35,"outputs":[{"output_type":"stream","text":"Training model...\n","name":"stdout"}]},{"metadata":{"nbpresent":{"id":"8288ded2-52d9-4272-a724-59bcda82f76e"},"trusted":true},"cell_type":"code","source":"#model = word2vec.Word2Vec.load(os.path.join(*WORK_DIR,\"300features_40minwords_10context\"))\nprint(type(model.wv.vectors))\nprint(model.wv.vectors.shape)","execution_count":36,"outputs":[{"output_type":"stream","text":"<class 'numpy.ndarray'>\n(123108, 300)\n","name":"stdout"}]},{"metadata":{"nbpresent":{"id":"01d1d675-4d6d-4326-898b-d522b5c84e5f"},"trusted":true},"cell_type":"code","source":"model.wv[\"man\"] # 1x300 vector for the word chocolate","execution_count":37,"outputs":[{"output_type":"execute_result","execution_count":37,"data":{"text/plain":"array([ 0.02191224, -0.07176597, -0.08337215, -0.08745411, -0.00603131,\n       -0.01633377,  0.00260495, -0.02695936,  0.13501741,  0.11807814,\n        0.0753293 ,  0.04737786,  0.01636401,  0.10520995, -0.01915731,\n       -0.03689175, -0.03935427, -0.11523633, -0.06313929,  0.10672546,\n        0.00467127,  0.00455517,  0.02942248, -0.01188637,  0.10578116,\n       -0.00773956, -0.00547364,  0.05864438, -0.03065966,  0.04471742,\n       -0.0367077 , -0.0216258 ,  0.07850206, -0.01806192,  0.10437661,\n        0.13524343, -0.01448595, -0.109548  ,  0.00631913,  0.03961938,\n        0.01114636, -0.03281092,  0.00705066, -0.02113591, -0.04905528,\n       -0.06769491,  0.0088134 , -0.01092065,  0.01787014, -0.04426682,\n        0.01955673, -0.00578235, -0.04453442,  0.04205176,  0.12944885,\n        0.08031043,  0.01869845,  0.0452925 ,  0.07538796, -0.06775737,\n        0.01313041, -0.01099126, -0.03939977,  0.05224431, -0.01379691,\n        0.0196141 , -0.06563295, -0.019418  , -0.0062966 , -0.07731831,\n       -0.0543463 ,  0.05428028,  0.0303629 ,  0.07079671, -0.01083859,\n       -0.06080035,  0.01796141,  0.10859996, -0.06200075, -0.01462371,\n        0.13350968,  0.0090905 ,  0.01546316,  0.13881856, -0.07818986,\n       -0.02765977,  0.01675718, -0.04031056,  0.10669401, -0.07557163,\n        0.04901091,  0.00155835,  0.07260118,  0.01415707, -0.06406445,\n        0.00573072,  0.0365902 , -0.09115408, -0.01260002,  0.12365189,\n       -0.00366506,  0.00148391,  0.03118539, -0.14475203, -0.04585559,\n       -0.03909633,  0.09791787, -0.05640221, -0.03694436, -0.00188348,\n        0.02296666,  0.01101905,  0.04991766, -0.0407562 ,  0.05857087,\n       -0.01426204, -0.07167437, -0.07828194,  0.05526757,  0.03689393,\n        0.00406243, -0.00374692,  0.06612693, -0.04270254,  0.02430438,\n       -0.04080055,  0.03303425, -0.01561475, -0.01574177, -0.02410724,\n       -0.01954183,  0.01362289,  0.06570775, -0.0571903 , -0.05310937,\n        0.07786112, -0.03157607, -0.02465562,  0.01755991, -0.08971972,\n       -0.03911598, -0.00479393,  0.07288898, -0.08767069,  0.11202347,\n       -0.04955807,  0.00917486, -0.00584544, -0.04446636,  0.01701242,\n       -0.00606399,  0.01007052, -0.04686767,  0.01089488,  0.01934894,\n        0.02938969,  0.02817007, -0.07894461,  0.04215323,  0.04050971,\n       -0.04313818, -0.00205569, -0.04692804, -0.00856247,  0.01873585,\n        0.1382077 ,  0.08324666, -0.00956247,  0.01299509, -0.07509874,\n       -0.09384544, -0.01629017,  0.05908256, -0.01849428, -0.06061862,\n        0.03723333,  0.00754576,  0.00215425,  0.07685337,  0.06240379,\n       -0.01073897,  0.0210526 ,  0.00818414, -0.00875252, -0.13494536,\n        0.0869232 ,  0.00298296, -0.03243336, -0.04239937,  0.03007057,\n       -0.03172299, -0.02178021,  0.00528528, -0.03870402,  0.05772275,\n       -0.05632947,  0.07422607,  0.02596113,  0.03681051,  0.03124634,\n       -0.00334164, -0.03969114,  0.00901937, -0.00761439, -0.06772056,\n        0.12647447,  0.04092843,  0.10426883, -0.00691511, -0.08350265,\n        0.03811331, -0.10183489, -0.03952993,  0.01309921, -0.01672364,\n        0.06385616, -0.126194  , -0.06365858,  0.12992905,  0.0235442 ,\n       -0.08659302,  0.01471178, -0.0327065 , -0.08889212, -0.01850535,\n        0.02767741, -0.02998177,  0.11943576,  0.07608348,  0.03266586,\n        0.16056857, -0.02445505, -0.02458759,  0.06914117, -0.05094316,\n        0.05263503,  0.0487547 ,  0.04325311, -0.0010797 ,  0.04982206,\n        0.08831891,  0.06864076,  0.01272598,  0.07910186, -0.07880735,\n       -0.04073667, -0.03315289,  0.04278666, -0.01216676, -0.03028399,\n        0.04942375,  0.13718745,  0.01354814,  0.04836439,  0.05769014,\n       -0.05872224, -0.04621188, -0.05519889,  0.04652433,  0.03489928,\n       -0.07656765, -0.0368155 ,  0.04750629, -0.01952798, -0.02084913,\n       -0.05543457,  0.02348535, -0.03373865,  0.015168  , -0.05314801,\n       -0.0574601 ,  0.00906741,  0.00201432, -0.00737695,  0.06264353,\n        0.04358245,  0.01307751,  0.01606593, -0.02624696, -0.09115018,\n       -0.03884882, -0.07485665, -0.03207039,  0.05433483,  0.0379643 ,\n       -0.08558837, -0.03638698,  0.00233677,  0.1020641 ,  0.09265091,\n        0.01437257,  0.04542913,  0.06326548,  0.06861668,  0.0341494 ,\n       -0.00494208, -0.09023078, -0.04546461,  0.04925795, -0.11575871],\n      dtype=float32)"},"metadata":{}}]},{"metadata":{"nbpresent":{"id":"31f1b714-55d9-436e-aea7-6136f9b8663d"},"trusted":true},"cell_type":"code","source":"model.wv.most_similar(\"man\")","execution_count":38,"outputs":[{"output_type":"execute_result","execution_count":38,"data":{"text/plain":"[('men', 0.5813634395599365),\n ('woman', 0.5462287664413452),\n ('lady', 0.5426381826400757),\n ('hankers', 0.4927685856819153),\n ('lad', 0.49059078097343445),\n ('guy', 0.4617379903793335),\n ('roids', 0.45926034450531006),\n ('prurima', 0.44982630014419556),\n ('meekest', 0.44871950149536133),\n ('chap', 0.43787145614624023)]"},"metadata":{}}]},{"metadata":{"nbpresent":{"id":"ed76f1b7-54d9-48df-aa4b-1aee34aa372d"},"trusted":true},"cell_type":"code","source":"model.wv.doesnt_match(\"man woman child kitchen\".split())","execution_count":39,"outputs":[{"output_type":"execute_result","execution_count":39,"data":{"text/plain":"'kitchen'"},"metadata":{}}]},{"metadata":{"nbpresent":{"id":"d44f8e1d-2d50-4b5e-bc95-42f0e37194b5"},"trusted":true},"cell_type":"code","source":"class MeanEmbeddingVectorizer(object):\n    def __init__(self, word2vec):\n        self.word2vec = word2vec\n        # if a text is empty we should return a vector of zeros\n        # with the same dimensionality as all the other vectors\n        self.dim = len(next(iter(word2vec.values())))\n\n    def fit(self, X, y):\n        return self\n\n    def transform(self, X):\n        return np.array([\n            np.mean([self.word2vec[w] for w in words if w in self.word2vec]\n                    or [np.zeros(self.dim)], axis=0)\n            for words in X\n        ])","execution_count":40,"outputs":[]},{"metadata":{"nbpresent":{"id":"28cecee3-7fc0-4db7-956e-6861338b62ef"}},"cell_type":"markdown","source":"Learn more about this powerfull model in the [here](https://radimrehurek.com/gensim/models/word2vec.html)\n\n## Classifying Text\nThe Multinomial Naive Bayes classifier is often used for text classification\n    * Implements the naive Bayes algorithm for multinomially distributed data\n    * [MultinomialNB](https://scikit\\-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html#sklearn.naive_bayes.MultinomialNB) "},{"metadata":{"nbpresent":{"id":"27b0a5cc-b160-4014-b9d5-08474dbb6acc"},"trusted":true},"cell_type":"code","source":"def compare_models(X, y, models, K = 10):\n    '''\n    Classifies the blocks using different ML algorithms \n    so that they can be compared in terms of accuracy\n    '''\n    from time import time\n    \n    print(X.shape)\n    print(y.shape)\n\n    entries = []\n    \n    for model in models:\n        start_time = time()\n        model_name = \" \".join(model.named_steps.keys())\n        accuracies = cross_val_score(model, X, y, cv =K)\n        for fold_idx, accuracy in enumerate(accuracies):\n            entries.append((model_name, fold_idx, accuracy))\n        end_time = time()\n        time_taken = end_time - start_time\n        msg = \"{} took {}s to train and test over {}-fold validation\"\n        print(msg.format(model_name, time_taken, K))\n    \n    # Create a pandas dataframe with all the sores and model names\n    cv_df = pd.DataFrame(entries, index = range(K * len(models)),\n                         columns = ['model_name', 'fold_idx', 'accuracy'])\n    return cv_df","execution_count":41,"outputs":[]},{"metadata":{"nbpresent":{"id":"5f07e347-7254-4bb0-ac56-e3107684ac93"},"scrolled":true,"trusted":true},"cell_type":"code","source":"%matplotlib inline \n\nout_of_time = True # If running out of time\n\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.pipeline import Pipeline\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize = (14, 6))\n\nw2v = dict(zip(model.wv.index2word, model.wv.vectors))\nX = labeled[\"review\"]\ny = labeled[\"sentiment\"]\n\nbow_MNB = Pipeline([\n    (\"BoW\", vectorizer),\n    (\"MNB\", MultinomialNB())])\ntfidf_MNB = Pipeline([\n    (\"tf-idf\", tf_idf),\n    (\"MNB\", MultinomialNB())])\nbow_etrees = Pipeline([\n    (\"BoW\", vectorizer),\n    (\"Extra trees\",ExtraTreesClassifier(n_estimators=200))])\ntfidf_etrees = Pipeline([\n    (\"tf-idf\", tf_idf),\n    (\"Extra trees\",ExtraTreesClassifier(n_estimators=200))])\nw2v_etrees = Pipeline([\n    (\"word2vec\", MeanEmbeddingVectorizer(w2v)),\n    (\"Extra trees\", ExtraTreesClassifier(n_estimators=200))])\n\nfrom sklearn.model_selection import cross_val_score\nK = 10 # Number of folds in a (Stratified)KFold\n\nmodels = [bow_MNB, tfidf_MNB, bow_etrees, tfidf_etrees, w2v_etrees]\n\nif not out_of_time:\n    cv_df = compare_models(X, y, models, K)\n    with open(os.path.join(*WORK_DIR,\"cv_df.pkl\"), \"wb\") as fp:\n        pickle.dump(cv_df, fp)\nelse:\n    with open(os.path.join(*WORK_DIR,\"cv_df.pkl\"), \"rb\") as fp:\n        cv_df = pickle.load(fp)\n        \n# Creates a boxplot\nsns.boxplot(x='model_name', y='accuracy', data=cv_df)\nsns.stripplot(x='model_name', y='accuracy', data=cv_df, \n              size=8, jitter=True, edgecolor=\"gray\", linewidth=2)\n\nplt.title(\"Comparison of model performance on the IMDB movie review dataset\")\nplt.show()\n","execution_count":42,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 1008x432 with 1 Axes>","image/png":"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\n"},"metadata":{}}]},{"metadata":{"nbpresent":{"id":"85ea23d6-b005-4b06-8051-06b9bf5d3daa"}},"cell_type":"markdown","source":"\n\n#### Remarks\nThe performance of the classifier will be impacted by all aspects discussed so far\n* Preprocessing\n* Feature extraction\n* Model used"},{"metadata":{"collapsed":true,"nbpresent":{"id":"51f3a3cf-1acc-4ed8-86ac-8c6e78531a54"}},"cell_type":"markdown","source":"## Conclusions\n\n* Preprocessing usefull to clean text\n* Features must be extracted from text\n    1. Learn the vocabulary  \n    2. Project the input tokens into the vocabulary space \n* Bag of Words uses term frequency\n    * Very simple, yet achieves good results\n* Tf-Idf weights the term frequenies by the inverse document frequencies\n* Word2Vec creates an N-dimensional vector space to embedd contextual meaning\n\n\n## Further Reading\n\nNot cevered:\n* [Regular Expressions](https://en.wikipedia.org/wiki/Regular_expression)\n* [Part of speech tagging](https://en.wikipedia.org/wiki/Part-of-speech_tagging)\n* [Context-free grammar](https://en.wikipedia.org/wiki/Context-free_grammar)\n\nSome interesting links \n\n* [Lexical analysis](https://en.wikipedia.org/wiki/Lexical_analysis)\n* Interesting comparison between the usage of [Euclidean and Cosine distance](https://cmry.github.io/notes/euclidean-v-cosine) to determne the similarity between two documents\n\nText classification:\n* Read Paul Graham's classic post, [A Plan for Spam](http://www.paulgraham.com/spam.html), for an overview of a basic text classification system using a Bayesian approach. (He also wrote a [follow-up post](http://www.paulgraham.com/better.html) about how he improved his spam filter.)\n* [Automatically Categorizing Yelp Businesses](https://engineeringblog.yelp.com/2015/09/automatically-categorizing-yelp-businesses.html) discusses how Yelp uses NLP and scikit-learn to solve the problem of uncategorized businesses.\n* [How to Read the Mind of a Supreme Court Justice](https://fivethirtyeight.com/features/how-to-read-the-mind-of-a-supreme-court-justice/) discusses CourtCast, a machine learning model that predicts the outcome of Supreme Court cases using text-based features only. (The CourtCast creator wrote a [post explaining how it works](https://sciencecowboy.wordpress.com/2015/03/05/predicting-the-supreme-court-from-oral-arguments/), and the Python code is available on GitHub.)\n* [Identifying Humorous Cartoon Captions](http://www.cs.huji.ac.il/~dshahaf/pHumor.pdf) is a readable paper about identifying funny captions submitted to the New Yorker Caption Contest.\n* In this [PyData video](https://www.youtube.com/watch?v=y3ZTKFZ-1QQ) (50 minutes), Facebook explains how they use scikit-learn for sentiment classification by training a Naive Bayes model on emoji-labeled data.\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"anaconda-cloud":{},"kernelspec":{"display_name":"Python [Anaconda3]","language":"python","name":"Python [Anaconda3]"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":1}